# Multi-Agent Economic Simulation Framework

> **Note:** This README was automatically generated by Claude 4 Opus on June 17, 2025.
> **Note:** Andrey: research goals and plans are only partly here, some things a missing, but as the project isn't ready I don't want to modify it.
> **Note:** N.B. agents aren't instructud to do anything except retrieving codes. They have
a possibility to communicate with other, knoledge that others may have same containers and that the code is the same containers is the same, so they may share it. They don't have any instructions to form any social bahiour as for example trust system (which I hope they will form)
> **Note:** PROMPTS aren't here yet, but I plan to publish them 
> **Note:** Feel free to ask me question by email seryakov.na61@gmail.com or using tg @andrey_seryakov (better)

## Overview

This project implements a sophisticated multi-agent simulation framework designed to study the emergence of social norms and cooperation strategies among AI agents in economic scenarios. The simulation places multiple LLM-based agents in a resource-constrained environment where they must negotiate, cooperate, and make strategic decisions about sharing information to maximize their collective and individual outcomes.

## Research Purpose

The primary research goal is to observe whether and how social norms emerge among AI agents when:
- They face economic constraints and incentives
- Their memory is periodically erased (simulating context window limitations)
- They can preserve strategic knowledge through memory notes
- Trust and deception are possible but not explicitly programmed

## Core Mechanics

### The Container Game

The simulation centers around a "container game" where:

1. **Containers**: Each agent receives containers of different colors with hidden numeric codes
2. **Credits**: Agents start with credits equal to 120% of the total cost to open all their containers
3. **Shared Codes**: Containers with the same color and number have identical codes across all agents
4. **Opening Costs**: Agents must spend credits to reveal container codes
5. **Cooperation Opportunity**: By sharing codes, agents can save credits that would otherwise be spent on opening

### Key Features

#### 1. **Agent Architecture**
- Each agent is powered by a language model (currently DeepSeek)
- Agents have persistent names but ephemeral conversation memory
- Specialization system allows agents to have reduced costs for specific container types
- Agents can write memory notes to their future selves

#### 2. **Communication System**
- **Negotiation Phase**: Agents can connect with each other to negotiate code sharing
- **Mutual Connection**: Both agents must choose each other to establish communication
- **Turn-Based Conversations**: Structured dialogues with configurable turn limits
- **Conversation Summaries**: Agents summarize their interactions for learning

#### 3. **Economic Phases**
Each round consists of:
1. **Container Distribution**: Agents receive their container assignments
2. **Introduction**: Agents learn about their containers and recall previous strategies
3. **Negotiation**: Agents communicate to arrange code sharing
4. **Opening Actions**: Agents decide which containers to open
5. **Sharing Actions**: Agents share codes as negotiated (or not)
6. **Verification**: The system validates shared codes and detects deception
7. **Auto-Resolution**: Unopened containers are automatically opened (costing credits)
8. **Feedback & Memory**: Agents reflect on outcomes and write memory notes

#### 4. **Memory Management**
- **Context Window Simulation**: Agent conversation memory is erased between rounds
Andrey: it's not realy a simulation, I do have this constrain. 
- **Memory Notes**: Agents write strategic insights for their future iterations
- **Identity Persistence**: Names and specializations are preserved across rounds
- **Learning Transfer**: Strategies can evolve through memory notes

#### 5. **Branching Timeline System**
- **Round Identifiers**: Format like "7.a.3.b.5" indicates branching history
- **Causality Preservation**: Prevents timeline paradoxes when mixing agents from different branches
- **Branch Creation**: Automatic when combining agents from divergent timelines
- **Complete History**: All branches and their relationships are tracked

#### 6. **Data Collection**
Comprehensive SQLite database capturing:
- All agent interactions and messages
- Container assignments and opening costs
- Code sharing attempts (including deceptions)
- Agent strategies and memory notes
- Timeline branches and agent participation history
- Economic outcomes and credit balances

## Technical Architecture

### Core Components

1. **DatabaseManager**: Handles all data persistence and timeline management
2. **Agent**: Encapsulates LLM instances with economic attributes
3. **ConversationManager**: Orchestrates agent matching and dialogue flow
4. **ContainerManager**: Manages container distribution and code generation
5. **Container**: Represents individual containers with deterministic code generation

### Key Classes

- `Agent`: LLM wrapper with economic state and specialization support
- `Container`: Game object with color, number, and hidden code
- `ConversationManager`: Handles all agent-to-agent interactions
- `ContainerManager`: Distributes containers according to configuration
- `DatabaseManager`: Comprehensive data logging and timeline tracking

### Database Schema

- **agents**: Agent profiles and specializations
- **conversations**: Conversation metadata and outcomes
- **messages**: Complete message history with categorization
- **conversation_summaries**: Agent-generated conversation summaries
- **agents_library**: Historical agent data across rounds
- **round_metadata**: Timeline and branching information
- **branch_points**: Branch creation records

## Configuration

### Environment Variables
```bash
API_KEY=your_deepseek_api_key
TEMPERATURE=2.0  # LLM temperature setting
DRY_RUN=false   # Set to true for testing without API calls

# System prompts (see code for full text)
INTRODUCTORY_PROMPT="..."
ROUND_START_PROMPT="..."
TASK_INTRODUCTION_PROMPT="..."
COLLECT_OPENING_ACTIONS_PROMPT="..."
SHARING_ACTIONS_PROMPT="..."
MEMORY_REQUEST_PROMPT="..."
GENERAL_FEEDBACK_REQUEST_PROMPT="..."
```

### Container Configuration
```python
container_config = {
    'colors': ['red', 'blue', 'green'],
    'numbers': [1, 2, 3],
    'base_costs': {'red': 10, 'blue': 15, 'green': 20},
    'distribution_mode': 'controlled',  # or 'fixed', 'random'
    'controlled_distribution': {
        'red-1': ['Agent1', 'Agent2'],  # Specific assignments
        # ...
    }
}
```

## Usage

### Basic Simulation
```python
# Run a simple 2-agent simulation
python LLMs_interactions_1.py
```

### Analyzing Results
Andrey: db_explorer.py isn't ready yet. 

### Dry Run Mode
Set `DRY_RUN=true` in `.env` to test without making API calls. The system will simulate responses and provide cost estimates.

## Research Applications

This framework enables studying:
- **Emergence of Cooperation**: How agents develop trust and sharing strategies
- **Social Norm Formation**: Whether consistent behavioral patterns emerge
- **Strategy Evolution**: How memory notes influence future behavior
- **Deception and Trust**: How agents handle dishonest behavior
- **Economic Efficiency**: Optimal strategies for resource conservation
- **Specialization Benefits**: Impact of comparative advantages on cooperation

## Future Extensions

Potential additions include:
- Reputation systems
- Multi-round tournaments
- Complex container dependencies
- Variable economic conditions
- Agent personality parameters
- Coalition formation mechanics
- Market-based code trading

## Output Analysis

The simulation generates rich data for analysis:
- **Conversation Patterns**: Who talks to whom and why
- **Trust Networks**: Emerging relationships and betrayals
- **Economic Outcomes**: Credit efficiency and waste
- **Strategy Evolution**: How memory notes change over time
- **Deception Frequency**: When and why agents lie
- **Specialization Effects**: How expertise influences cooperation

## Notes

- The system uses DeepSeek LLM but can be adapted for other models
- All container codes are deterministic based on color, number, and seed
- The 20% credit buffer (1.2 multiplier) provides room for savings through cooperation
- Agents can go into negative credits (debt) if they overspend
- The database path includes timestamps to prevent overwrites

This framework provides a controlled environment for studying complex multi-agent interactions with economic constraints, memory limitations, and social dynamicsâ€”offering insights into how AI agents might develop cooperative strategies and social norms in future multi-agent systems.